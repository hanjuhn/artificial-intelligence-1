{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JgD4tTO1T5zX"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# 생성자 모델 만들기\n","generator = Sequential()\n","# 7x7x128 크기의 feature map을 생성\n","generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n","generator.add(BatchNormalization())\n","generator.add(Reshape((7, 7, 128)))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(64, kernel_size=5, padding='same'))\n","generator.add(BatchNormalization())\n","generator.add(Activation(LeakyReLU(0.2)))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n"],"metadata":{"id":"hFvQnpshUA4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 판별자 모델 만들기\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Flatten())\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n","discriminator.trainable = False"],"metadata":{"id":"-tVAR57hUGw_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성자와 판별자 연결\n","ginput = Input(shape=(100,))\n","dis_output = discriminator(generator(ginput))\n","gan = Model(ginput, dis_output)\n","gan.compile(loss='binary_crossentropy', optimizer='adam')\n","gan.summary()"],"metadata":{"id":"KohqfsiuUIno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 함수 정의\n","def gan_train(epoch, batch_size, saving_interval):\n","    (X_train, _), (_, _) = mnist.load_data()\n","    X_train = X_train.reshape(-1, 28, 28, 1).astype('float32')\n","    X_train = (X_train - 127.5) / 127.5  # 원래 mnist 데이터 값의 범위인 0에서 255 사이의 값을 -1부터 1 사이로 바꿔줌\n","\n","    true = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","\n","    for i in range(epoch):\n","        idx = np.random.randint(0, X_train.shape[0], batch_size)\n","        imgs = X_train[idx]\n","        d_loss_real = discriminator.train_on_batch(imgs, true)\n","\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        gen_imgs = generator.predict(noise)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        g_loss = gan.train_on_batch(noise, true)  # 노이즈를 넣고 이게 진짜야 라고 속여야 한다\n","\n","        print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n","\n","        if i % saving_interval == 0:\n","            noise = np.random.normal(0, 1, (25, 100))\n","            gen_imgs = generator.predict(noise)\n","            gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","            fig, axs = plt.subplots(5, 5)\n","            count = 0\n","            for j in range(5):\n","                for k in range(5):\n","                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n","                    axs[j, k].axis('off')\n","                    count += 1\n","            fig.savefig(\"gan_mnist_%d.png\" % i)\n","\n","# 학습 실행\n","gan_train(2001, 32, 200)"],"metadata":{"id":"apP947iKUM8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모드 붕괴 -> 생성자와 감별자 모델의 성능이 같이 올라가야 좋은 결과가 잘 나오는데 지금 위 코드는 생성자와 감별자 성능이 둘 다 똑같이 안 올라가서 문제다"],"metadata":{"id":"sLWGg-U7jsyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import fashion_mnist\n","(X_train, _), (_, _) = fashion_mnist.load_data()\n","X_train = X_train.reshape(-1, 28, 28, 1).astype('float32')\n","X_train = (X_train - 127.5) / 127.5"],"metadata":{"id":"4fsvmKLAUk4h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","(X_train, _), (_, _) = cifar10.load_data()\n","X_train = X_train.astype('float32')\n","X_train = (X_train - 127.5) / 127.5"],"metadata":{"id":"ASbDxyTnU-fW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"],"metadata":{"id":"EC3epiXyIcUt"},"execution_count":null,"outputs":[]}]}