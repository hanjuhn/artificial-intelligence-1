{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzCcUpWKzrrh"
   },
   "outputs": [],
   "source": [
    "!pip install tf_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSO_Oht91WAP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# XAI 알고리즘을 불러오는 부분입니다.\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
    "\n",
    "# 이미지를 불러와 보여 주는 데 쓰는 라이브러리를 불러옵니다.\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다.\n",
    "!git clone https://github.com/taehojo/data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fJZw9Iu6eO_"
   },
   "outputs": [],
   "source": [
    "# 원본 이미지가 들어갈 리스트를 만듭니다.\n",
    "images_originals = []\n",
    "\n",
    "# 원본 이미지가 저장된 폴더에서 하나씩 불러와 리스트에 넣습니다.\n",
    "for img_path in glob.glob('./data/img/*_0.jpg'):\n",
    "    images_originals.append(mpimg.imread(img_path))\n",
    "\n",
    "# 코랩에서 보여 줄 이미지의 크기\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# 원본 이미지를 코랩에서 보이게 하기\n",
    "for i, image_o in enumerate(images_originals):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8m72HWrK-bC"
   },
   "outputs": [],
   "source": [
    "# 사전에 학습된 딥러닝 모델 불러오기\n",
    "model = VGG16(weights=\"imagenet\", include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaN40nDcK_4M"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1HXI2NO6isC"
   },
   "outputs": [],
   "source": [
    "# 사전에 학습된 딥러닝 모델 불러오기\n",
    "model = VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "# 원본 이미지 이름과 Imagenet에서의 해당 이미지 인덱스\n",
    "input_list = [\"maltese\", \"persian_cat\", \"squirrel_monkey\", \"grand_piano\", \"yawl\"]\n",
    "imagenet_index = [\"153\", \"283\", \"382\", \"579\", \"914\"]\n",
    "\n",
    "# 그래이디언트 CAM 알고리즘 선택\n",
    "explainer = GradCAM()\n",
    "target_layer = \"block5_conv3\"\n",
    "\n",
    "# 그래이디언트 CAM 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기\n",
    "images_cams = []\n",
    "\n",
    "# 그래이디언트 CAM 알고리즘 실행\n",
    "for l, i in zip(input_list, imagenet_index):\n",
    "    # 이미지를 불러오고 내부에서 처리하기 위해 이미지의 크기를 설정합니다.\n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224))\n",
    "    img = img_to_array(img)          # 이미지를 넘파이 배열로 바꿉니다.\n",
    "    data = ([img], None)\n",
    "\n",
    "    # 그래이디언트 CAM이 실행되는 부분입니다.\n",
    "    grid = explainer.explain(\n",
    "        data, model, class_index=int(i), layer_name=target_layer\n",
    "    )\n",
    "\n",
    "    # 실행 후 저장되는 이름입니다.\n",
    "    explainer.save(grid, \".\", './data/img/{}_cam.jpg'.format(l))\n",
    "\n",
    "# 그래이디언트 CAM 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_cam.jpg'):\n",
    "    images_cams.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image_c in enumerate(images_cams):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2wMJ1Yf6pSU"
   },
   "outputs": [],
   "source": [
    "# 오클루전 알고리즘 선택\n",
    "explainer = OcclusionSensitivity()\n",
    "\n",
    "# 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기\n",
    "images_occ1s = []\n",
    "\n",
    "# 패치 크기를 정합니다.\n",
    "patch_size = 40\n",
    "\n",
    "# 오클루전 알고리즘 실행\n",
    "for l, i in zip(input_list, imagenet_index):\n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    data = ([img], None)\n",
    "    grid = explainer.explain(data, model, int(i), patch_size)\n",
    "    explainer.save(grid, \".\", './data/img/{}_occ1.jpg'.format(l))\n",
    "\n",
    "# 오클루전 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_occ1.jpg'):\n",
    "    images_occ1s.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image in enumerate(images_occ1s):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti4QhXbe6sRZ"
   },
   "outputs": [],
   "source": [
    "# 오클루전 알고리즘 선택\n",
    "explainer = OcclusionSensitivity()\n",
    "\n",
    "# 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기\n",
    "images_occ1s = []\n",
    "\n",
    "# 패치 크기를 수정합니다.\n",
    "patch_size = 20\n",
    "\n",
    "# 오클루전 알고리즘 실행\n",
    "for l, i in zip(input_list, imagenet_index):\n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    data = ([img], None)\n",
    "    grid = explainer.explain(data, model, int(i), patch_size)\n",
    "    explainer.save(grid, \".\", './data/img/{}_occ1.jpg'.format(l))\n",
    "\n",
    "# 오클루전 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_occ1.jpg'):\n",
    "    images_occ1s.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image in enumerate(images_occ1s):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
